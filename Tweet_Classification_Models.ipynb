{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models for Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import _pickle as pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the DF\n",
    "with open(\"main_df.pkl\",'rb') as fp:\n",
    "    main_df = pickle.load(fp)\n",
    "\n",
    "# Loading in the cleaned tweet data\n",
    "with open(\"clean_tweets.pkl\",'rb') as fp:\n",
    "    data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "### Train, test, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data, main_df.City\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "tf_idf_data_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "tf_idf_data_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Models\n",
    "* Dummy Classifier - baseline\n",
    "* Naive Bayes\n",
    "* Random Forest\n",
    "* Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier - Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier\n",
      "Training Accuracy: 0.49650262303272547 \t\t Testing Accuracy: 0.4905094905094905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dm_class = DummyClassifier()\n",
    "\n",
    "dm_class.fit(tf_idf_data_train, y_train)\n",
    "dm_train_preds = dm_class.predict(tf_idf_data_train)\n",
    "dm_test_preds = dm_class.predict(tf_idf_data_test)\n",
    "\n",
    "dm_train_score = accuracy_score(y_train, dm_train_preds)\n",
    "dm_test_score = accuracy_score(y_test, dm_test_preds)\n",
    "\n",
    "print('Dummy Classifier')\n",
    "print(f\"Training Accuracy: {dm_train_score} \\t\\t Testing Accuracy: {dm_test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Training Accuracy: 0.9728 \t\t Testing Accuracy: 0.6169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rf_classifier.fit(tf_idf_data_train, y_train)\n",
    "rf_train_preds = rf_classifier.predict(tf_idf_data_train)\n",
    "rf_test_preds = rf_classifier.predict(tf_idf_data_test)\n",
    "\n",
    "rf_train_score = accuracy_score(y_train, rf_train_preds)\n",
    "rf_test_score = accuracy_score(y_test, rf_test_preds)\n",
    "\n",
    "print('Random Forest')\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(rf_train_score, rf_test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Parameters to be tested\n",
    "rf_param_grid = {'n_estimators': [10,30, 60,100],\n",
    "                 'criterion': ['gini', 'entropy'],\n",
    "                 'max_depth': [None, 2, 5, 10],\n",
    "                 'min_samples_split': [5,10],\n",
    "                 'min_samples_leaf': [1, 2, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Searching\n",
    "rf_grid_search = GridSearchCV(rf_classifier, rf_param_grid, cv=3, return_train_score=True, verbose=2)\n",
    "rf_grid_search.fit(tf_idf_data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_search = GridSearchCV(rf_classifier, rf_param_grid, cv=3, return_train_score=True, verbose=2)\n",
    "rf_grid_search.fit(tf_idf_data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_leaf=1, min_samples_split=10)\n",
    "\n",
    "rf_classifier.fit(tf_idf_data_train, y_train)\n",
    "rf_train_preds = rf_classifier.predict(tf_idf_data_train)\n",
    "rf_test_preds = rf_classifier.predict(tf_idf_data_test)\n",
    "\n",
    "rf_train_score = accuracy_score(y_train, rf_train_preds)\n",
    "rf_test_score = accuracy_score(y_test, rf_test_preds)\n",
    "\n",
    "print('Random Forest with GridSearch')\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(rf_train_score, rf_test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Training Accuracy: 0.823 \t\t Testing Accuracy: 0.6049\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "nb_classifier.fit(tf_idf_data_train, y_train)\n",
    "nb_train_preds = nb_classifier.predict(tf_idf_data_train)\n",
    "nb_test_preds = nb_classifier.predict(tf_idf_data_test)\n",
    "\n",
    "nb_train_score = accuracy_score(y_train, nb_train_preds)\n",
    "nb_test_score = accuracy_score(y_test, nb_test_preds)\n",
    "\n",
    "print(\"Multinomial Naive Bayes\")\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(nb_train_score, nb_test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Training Accuracy: 0.8202598051461404 \t\t Testing Accuracy: 0.6123876123876124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_class = LogisticRegression()\n",
    "\n",
    "lr_class.fit(tf_idf_data_train, y_train)\n",
    "lr_train_preds = lr_class.predict(tf_idf_data_train)\n",
    "lr_test_preds = lr_class.predict(tf_idf_data_test)\n",
    "\n",
    "lr_train_score = accuracy_score(y_train, lr_train_preds)\n",
    "lr_test_score = accuracy_score(y_test, lr_test_preds)\n",
    "\n",
    "print('Logistic Regression')\n",
    "print(f\"Training Accuracy: {lr_train_score} \\t\\t Testing Accuracy: {lr_test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters to grid search\n",
    "log_param_grid = {'C': [1.5**n for n in range(0, 20, 2)],\n",
    "                  'fit_intercept': [True, False],\n",
    "                  'intercept_scaling': [1, 5, 10, 25, 50, 100],\n",
    "                  'solver': ['liblinear', 'saga']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_grid_search = GridSearchCV(lr_class, log_param_grid, cv=3, return_train_score=True, verbose=3)\n",
    "log_grid_search.fit(tf_idf_data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Testing Accuracy: {log_grid_search.best_score_*100}\")\n",
    "print(f\"Optimal Parameters: {log_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_class = log_grid_search.best_estimator_\n",
    "\n",
    "lr_class.fit(tf_idf_data_train, y_train)\n",
    "\n",
    "lr_train_preds = lr_class.predict(tf_idf_data_train)\n",
    "lr_test_preds = lr_class.predict(tf_idf_data_test)\n",
    "\n",
    "lr_train_score = accuracy_score(y_train, lr_train_preds)\n",
    "lr_test_score = accuracy_score(y_test, lr_test_preds)\n",
    "\n",
    "print('Logistic Regression with GridSearch')\n",
    "print(f\"Training Accuracy: {lr_train_score} \\t\\t Testing Accuracy: {lr_test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = text.Tokenizer(num_words=20000)\n",
    "# tokenizer.fit_on_texts(list(main_df.tweet))\n",
    "# list_tokenized_headlines = tokenizer.texts_to_sequences(main_df.tweet)\n",
    "# X_t = sequence.pad_sequences(list_tokenized_headlines, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(X)\n",
    "list_tokenized_tweets = tokenizer.texts_to_sequences(X)\n",
    "X_t = sequence.pad_sequences(list_tokenized_tweets, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 500\n",
    "input_ = Input(shape=(100,))\n",
    "x = Embedding(1000, embedding_size)(input_)\n",
    "x = LSTM(50, return_sequences=True)(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# There are 2 different possible classes, so we use 2 neurons in our output layer\n",
    "x = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=input_, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 100, 500)          500000    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100, 50)           110200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 612,852\n",
      "Trainable params: 612,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8006 samples, validate on 2002 samples\n",
      "Epoch 1/10\n",
      "8006/8006 [==============================] - 14s 2ms/step - loss: 0.6823 - accuracy: 0.5901 - val_loss: 0.8939 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 0.6696 - accuracy: 0.6180 - val_loss: 1.0330 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 0.6719 - accuracy: 0.6227 - val_loss: 1.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "8006/8006 [==============================] - 14s 2ms/step - loss: 0.6675 - accuracy: 0.6233 - val_loss: 0.9565 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "8006/8006 [==============================] - 14s 2ms/step - loss: 0.6665 - accuracy: 0.6239 - val_loss: 0.8982 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "8006/8006 [==============================] - 14s 2ms/step - loss: 0.6677 - accuracy: 0.6189 - val_loss: 0.8733 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "8006/8006 [==============================] - 15s 2ms/step - loss: 0.6680 - accuracy: 0.6207 - val_loss: 0.9051 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "8006/8006 [==============================] - 14s 2ms/step - loss: 0.6659 - accuracy: 0.6207 - val_loss: 0.9336 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "8006/8006 [==============================] - 14s 2ms/step - loss: 0.6653 - accuracy: 0.6233 - val_loss: 0.9401 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 0.6622 - accuracy: 0.6242 - val_loss: 0.9179 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3d9eeac8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_t, y, epochs=10, batch_size=2000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
